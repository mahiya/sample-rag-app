[
  {
    "id": "1836108400811529412-airindia-azure-ai-search-travel-and-transportation-en-india",
    "content": "As part of a transformation intended to restore its status as a world-class airline with a strong Indian identity, Air India needed to upgrade the customer experience without increasing costs.\n\nAir India used Azure OpenAI Service to develop AI.g, one of the world’s first airline virtual assistants based on generative AI. Launched in May 2023, it has handled nearly 4 million customer queries and complements other innovative AI-based services.\n\nAs Air India has doubled its passenger count, AI.g has handled 97% of queries with full automation and avoided millions of dollars in customer support costs. Generative AI in multiple applications is positioning the airline for continued growth.\n\nAir India, the nation’s flagship carrier, is midway through a five-year transformation to renewed profitability and the global leadership that has been a source of national pride. Over decades, the nearly century-old airline underwent management and other changes that left its fleet and technology outdated. That resulted in a less-than-ideal experience for millions of passengers who fly with Air India annually. The transformation is designed to address prior shortfalls and dramatically improve customer service.\n\n“Customers are the very center of our existence,” says Dr. Satya Ramaswamy, Chief Digital and Technology Officer at Air India. “We anticipate a many-fold increase in passengers, and they’re coming with certain expectations. We need to deliver. Happy customers are loyal customers.”\n\nIn 2022, under new ownership by the Tata Group, the airline ordered 470 new planes and set out to recover its original reputation for taking care of people. The effort included a modernization that migrated all the airline’s workloads, including a new website, from its on-premises datacenters to Microsoft Azure.\n\nRamaswamy explains, “We want to adopt the latest technologies available to us to provide the consistent, quick, and accurate service that our customers expect from us.”\n\nTo enhance customer service without increasing support costs, the airline decided to upgrade its virtual assistant, which was based on outdated technologies. “When OpenAI models were offered on Azure, we didn’t have a second thought,” says Viju Chacko, Head of Digital Architecture at Air India. “It was the next obvious step.”\n\nThe company’s confidence was bolstered by successful experience with Microsoft 365 Copilot. Air India began working with Azure OpenAI Service and Azure AI services to update the existing assistant’s core natural language processing engine to the latest GPT models. The airline also reengineered its AI stack for generative content and more back-end integration. It used Azure AI Content Safety to detect and mitigate potentially harmful content to help ensure a safe and responsible virtual assistant.\n\n“We have to be very accurate with information and careful about some of the potential challenges with generative AI,” says Ramaswamy. He cites Retrieval Augmented Generation (RAG) and integration with the airline’s back-end systems as keys to ensuring the assistant’s responses are accurate, appropriate, and actionable.\n\nThe airline built a multi-modal AI platform that includes Azure AI Search, Azure AI Speech, and Azure AI Vision on a foundation of Azure data solutions. AI Search works with Azure OpenAI to support RAG, while Azure Cosmos DB delivers scalable storage of virtual assistant conversations, user states, and vectors. It also serves most of Air India’s other non-relational database needs, including booking data. Chacko says, “For use cases where we want a dynamically scaling database, especially for NoSQL data, Azure Cosmos DB is our choice. With our virtual assistant in particular, we have experienced the higher scale, higher availability, and faster time to market of using Azure Cosmos DB.” Azure SQL Database helps evaluate the assistant’s conversations. The platform also interfaces with other data solutions in the company’s architecture, including Azure Database for PostgreSQL and Azure Databricks.\n\nThis data foundation supports a highly capable virtual assistant, with Azure App Service helping to ensure fast, easy deployment. Chacko explains, “The solution is implemented as multiple microservices, including the bot code and natural language processing service that works with Azure OpenAI. All are deployed using Azure App Service.” In that microservices environment, Azure API Management helps provide security for sensitive customer data.\n\nChacko says, “Azure API Management is one of the services we rely on to expose our APIs and manage them in a very secure fashion with all the security layers mandated by our enterprise security team.”\n\nIn May 2023, Air India launched its new assistant, now called AI.g, as one of the industry’s first virtual agents based on generative AI and informed by the airline’s enterprise data. Ramaswamy says, “We built a bunch of innovations to make sure the information provided by the chatbot is well integrated into our enterprise systems, such as our reservation system.”\n\nAI.g handles an average of 30,000 questions per day across 1,300 topic areas related to bookings, flight status, baggage, check-in, frequent flyer awards, airport lounge access, and more. Chacko notes, “For every business requirement, we were able to figure out how we could realize it on the Azure platform. The support from Microsoft has been amazing, both in terms of technical support and co-innovating solutions together.”\n\nTo customers’ delight, the virtual assistant recognizes colloquial or incomplete requests such as “Can I bring my Labrador, Max, with me?” that may stymie other virtual assistants. Ramaswamy explains, “This is possible because Azure OpenAI Service has the ability to reason that a Labrador is a dog, a dog is a pet, and therefore the pet policy applies. And it gives a beautiful answer that includes the name of the dog along with the policies.”\n\nTo date, AI.g has successfully handled nearly 4 million customer queries, 97% of them with full automation. When it detects the need for additional support, it automatically escalates to contact center staff.\n\n“Customer convenience and the ability to get things accomplished more quickly and accurately is why customers prefer to interact with AI.g,” says Ramaswamy. “It has also freed our contact center team to focus on customers who need to be assisted by a human agent and those who prefer to call.”\n\nThe Azure-powered AI platform also supports Air India customers in other innovative ways. Travelers can save time by scanning visas and passports during web check-in, then scan baggage tags to track their bags throughout their journeys. The platform’s voice recognition also enables analysis of live contact center conversations for quality assurance, training, and improvement. Chacko explains, “The multi-modality helps us realize the multimedia aspects of these interactions.”\n\nConversational AI based on Azure OpenAI Service has improved the Air India customer experience, enabled the airline to upscale customer support without increasing the number of human agents, and empowered those agents to personalize their support while limiting costs and supporting business growth.\n\n“We have doubled our passenger count since early 2022,” says Ramaswamy. “But the call volume in our contact center remains the same—about 9,000 queries daily. That’s because AI.g is handling about 10,000 a day. That saves us several million dollars a year. And AI.g would not have been possible without strong collaboration with Microsoft.”\n\nHe adds that Air India’s confidence in the responsibility of its Azure-driven AI was well founded. “We have not had one single instance in more than a year and a half when AI.g did anything inappropriate.”\n\nThe company is now working on AI-powered projects to improve efficiency and enhance training for crew and pilots. For instance, Ramaswamy describes how contact center staff must speak to customers while simultaneously looking up or entering information in various systems. He says, “We envision a feature where the agents talk to customers with empathy, truly understanding their needs, while our AI listens to perform all the data entry and retrieval.”\n\nAs Air India continues to innovate and expand its AI capabilities, it is set to achieve its goal of becoming a global leader in aviation and reach its target of 30% market share. Ramaswamy says, “We are on this mission of building a world-class airline with an Indian heart. To accomplish that goal, we are becoming an AI-infused company, and our collaboration with Microsoft is making that happen.”\n\nDiscover more about Air India on Facebook, Instagram, LinkedIn, X/Twitter, and YouTube."
  },
  {
    "id": "1835632683895630292-nba-azure-sql-database-media-and-entertainment-en-united-states",
    "content": "Celebrating the game of basketball through many channels, including events and broadcasts, the NBA needed a better way to access data, moving onto a unified platform to scale on demand and use AI-driven capabilities, such as high performance.\n\nThe NBA chose Microsoft Azure as its trusted cloud platform, providing advanced security, scalability, and speed to drive innovation.\n\nAzure is transforming how the NBA plans and builds new solutions, making the business more resilient and propelling it forward.\n\nWe have our NBA content available to our fans on every platform out there in the marketplace. We saw an opportunity to utilize data more effectively to improve our user experience. Our broadcast engineers, operations teams and developers rely on data to make informed decisions. Unifying this data to deliver advanced analytics is the foundation to our success. Our teams are capturing, storing and analyzing data throughout our entire ecosystem and with that massive workload we needed a foundation that is resilient and secure with the ability to process information in real time. Azure delivers a seamless data experience throughout the organization and allows the NBA to scale up on demand. Integration of AI tools allows us to create new solutions to localize highlights, translate content into multiple languages, and create personalized experiences. It truly has enabled us to extract and transform the copious amounts of data that we have. It also allows us to ensure we have uniformity across all of this data to keep a consistent and optimal fan experience. The impact on our global audience has been absolutely tremendous. We can now deliver to our fans in 16 languages in more than 200 countries, allowing them to deepen their connection to the NBA. With Microsoft, we've intertwined AI services into every facet of our infrastructure. So we just have to worry about delivering what we do best and that's basketball.\n\nThe National Basketball Association (NBA) is a global sports and media powerhouse, dedicated to growing and celebrating the game of basketball. With millions of fans worldwide, the NBA has a mission to bring fans closer to the game they love through various platforms, including events, broadcasts, and digital experiences.\n\nTo continue delivering more personalized fan experiences, the NBA needed to harness vast amounts of data throughout the organization. However, the scale, complexity, and security required for next-generation technologies compelled the league to explore new opportunities.\n\n“Our broadcast engineers, operations teams, and developers rely on data to make informed decisions. Unifying this data to deliver innovation is the foundation to our success,” says Keith Cafferty, Associate Vice President of DTC Product, Technology & Operations at the NBA.\n\nLaying the foundation for innovation by colocating in cloud\n\nTo overcome these challenges, the NBA migrated its IT estate to Microsoft Azure, unifying its data in the cloud to more easily build and run AI models. With the migration to Azure, the NBA can colocate data, applications, and infrastructure, accelerating AI advancements, unlocking data insights, and making faster time to market possible for new experiences and innovative features.\n\nThe NBA’s collaboration with Microsoft gave the league the agility to scale resources on demand during major events, ensuring smooth performance during peak times. If viewership spikes on any platform, the NBA can quickly pivot, providing fans with uninterrupted access to real-time action. The migration involved modernizing its code and data using Windows Server on Azure, Azure Blob Storage, Azure App Service, and Azure SQL Database, boosting productivity and scalability.\n\n“On Azure, our teams are capturing, storing, and analyzing data to build products and distribute statistics and analytics throughout our entire ecosystem, including the NBA App, insights for coaches and players, and our direct-to-consumer platform and products,” says Ken DeGennaro, Senior Vice President of Media Operations and Technology at the NBA.\n\nSecurity and resilience are paramount. By using AI-infused cloud-native services, the NBA is innovating within a trusted environment that offers built-in controls across data, networking, and apps. In addition, Microsoft Defender for Cloud provides a single pane of glass for visibility into the NBA’s cloud security posture.\n\nFuture-proofing the business for its global audience\n\nSince migrating to Azure, the NBA has experienced numerous positive outcomes. The unified platform supports efficient resource management, empowering developers to use AI solutions more securely and quickly. The NBA’s technology investments are future-proof, driving continuous innovation throughout the organization.\n\nThe impact on fan engagement is significant. By unlocking data to power their AI applications, the NBA can deliver personalized content and experiences, enhancing fans’ interactions with the game. The seamless application of AI tools to the NBA’s platform is transformative, because the league can localize highlights, translate content into multiple languages, and create unique experiences for fans around the world.\n\n“The impact of using Azure for our global audience has been tremendous, as we now engage with fans in 60 languages in more than 200 countries, deepening the personal connection to the NBA,” says Jon Hurwitz, Director of Product, Basketball Data, Search & AI at the NBA.\n\nWith plans to continue innovating throughout the organization, the NBA has launched several new AI-driven features, including NBA Insights, which highlights the “why” behind key game moments, and NBA Stats, which analyzes on-court player movements to deepen a fan’s understanding of the game.\n\nBy migrating to Azure, the NBA has addressed its infrastructure challenges and positioned itself at the forefront of innovation with AI. The transformation of its digital ecosystem is bringing fans closer to the game they love and ensuring a bright future for basketball."
  },
  {
    "id": "1835736865947806376-abnamro-azure-devops-banking-and-capital-markets-en-netherlands",
    "content": "ABN AMRO Bank was already operating several chatbots but wanted to explore a new platform that would allow them to better implement AI capabilities. After a competitive RFP process, ABN AMRO transitioned to Microsoft Copilot Studio. The new platform has been used for the bank’s customer-facing “Anna” agent and the “Abby” agent, which provides support to the bank’s employees.\n\nThe new agents are consistently delivered high customer satisfaction. The accuracy rate for intent recognition was increased by 7% for Dutch, leading to more precise and reliable interactions. With Microsoft Copilot Studio, ABN AMRO also sees faster time to market for improvements to its new agents.\n\nABN AMRO Bank is the third-largest bank in The Netherlands, with headquarters in Amsterdam. With over 22,000 employees, ABN AMRO serves over 5 million retail customers and 365,000 commercial clients across 15 countries. \n\nIts operations include a private banking division as well as commercial and merchant banking operations that play a major role in energy, commodities and transportation markets. \n\nThe bank, which was already operating several chatbots, wanted to explore a new platform that would allow them to better implement AI capabilities. “With the rapid introduction of Generative AI, we anticipate that our customers are going to expect much more from a chatbot and we wanted to get ahead of that demand,” says Bobby van Groningen, IT Lead at ABN AMRO. \n\nAfter a competitive RFP process in late 2023, ABN AMRO transitioned to Microsoft Copilot Studio. “Microsoft’s leadership and innovation in the AI space led us to select Microsoft Copilot Studio,” says van Groningen. “We also liked that many of the chatbot capabilities we needed were available out of the box. This contributed to an intuitive and easy-to-use development experience.” \n\nSecurity was another important consideration. As van Groningen explains, “Together with our CISO team, we conducted an extensive, 3-month review and confirmed that Microsoft Copilot Studio met our stringent security requirements.” (Copilot Studio follows a number of security and governance controls and processes, including geographic data residency, data loss prevention, multiple standards certifications, regulatory compliance, environment routing, and regional customization.)\n\nABN AMRO’s transition to Copilot Studio covered both the bank’s customer-facing “Anna” chatbot – operating across text and voice channels – and the “Abby” chatbot, which provides support to the bank’s employees. Copilot Studio was used to create ‘agents’ – a new kind of AI-driven, natural-language experience that replaced the original chatbots. \n\nThe “Anna” agent supports over 2 million text conversations and 1.5 million voice conversations with customers every year and can cover a wide variety of topics – from help with unblocking a debit card or changing the withdrawal limit at an ATM – to navigating through the services provided in ABN AMROs digital bank. The “Abby” agent covers internal questions such as IT Helpdesk support and facilities services.  \n\nThe migration to Copilot Studio was completed in just 6 months – driven by a successful partnership with Microsoft and Capgemini. “We helped anchor the partnership with our team and the ABN AMRO team, laying the groundwork for a successful implementation,” says Mark Oost, Vice President AI & Generative AI, Insights & Data at CapGemini. \n\nThese projects also fostered a close collaboration between ABN AMRO and Microsoft, resulting in significant product improvements and enhancements. Together, the teams achieved faster user experiences, enhanced dialog management capabilities, and reduced latency, driving the success of ABN AMRO’s digital transformation and setting new standards for performance and efficiency.\n\nABN AMRO's adoption of Copilot Studio is now central to the bank’s solution architecture. Chat interactions are passed from ABN AMRO Bank’s Azure middleware and Contact Center as a Service (CCaaS) platform which is used for both the voice and text channels of the Anna agent. Voice calls are processed in Azure Communication Services (ACS) before the middleware.\n\nThe middleware layer further enhances these interactions by leveraging Microsoft Copilot Studio as the dialog manager, integrated with Azure AI Conversational Language Understanding (CLU) for precise intent recognition and entity extraction. With Copilot Studio, the conversational IVR on the voice channel is able to understand customer inquiries and route them to the correct call center department. Additionally, it can fully resolve certain queries without escalating to a live agent, enhancing operational efficiency and customer satisfaction.\n\nTo support continuous integration and continuous delivery (CI/CD), ABN AMRO utilizes Azure DevOps in conjunction with Power Platform Build Tools. This technical setup facilitates efficient development, testing, and deployment processes, enabling rapid and reliable updates. The architecture’s scalability and integration with advanced AI capabilities allow ABN AMRO to continuously innovate, enhancing their customer-facing and employee-support solutions.\n\nSince migrating to Copilot Studio and deploying its new agents, ABN AMRO is enjoying several key benefits, including: \n\nEnhanced customer and employee experiences: The Anna agent, operating across both text and voice channels, has consistently delivered high customer satisfaction, while the IVR bot experienced reduced drop-off and transfer rates. The Abby agent, supporting internal employee needs, became a more effective and dependable tool, contributing to an overall streamlined userexperience.\n\nSuperior accuracy in language processing: By integrating Azure AI Conversational Language Understanding (CLU) with Copilot Studio, ABN AMRO increased its accuracy rate in intent recognition by 7% for Dutch, leading to more precise and reliable customer and employee interactions. \n\nFaster time to market: As demonstrated by the 6-month migration, ABN AMRO foresees faster time to market for improvements and added functionality to its new agents plus faster launch of new products, including integration with other Power Platform products.\n\nWith Copilot Studio’s robust architecture, ABN AMRO is well-positioned to integrate advanced AI features, including Retrieval-Augmented Generation (RAG) patterns, and future developments like Large Language Models (LLMs) as the orchestration layer for intent recognition.\n\n“ABN AMRO has created a maturity model towards having even more natural and productive conversations with our customers. This will be implemented via a combination of great features in Copilot Studio as well as strong Azure Services, like OpenAI models and Azure Search,” says van Groningen. \n\nLooking to the future, ABN AMRO is already planning agents for other areas of the business. “Thanks to the efficiency of Microsoft Copilot Studio, we’re now able to develop chatbot support for a wide range of business applications – and get them into production very quickly,” says van Groningen. \n\nEqually exciting is that the bank’s next new agent will be set up as a full, Generative AI agent. The project will also be used as a testing ground for similar, Generative AI-driven experiences in Anna. As van Groningen notes, “At ABN AMRO, we are just beginning our joint Generative AI journey. But with Microsoft Copilot Studio, we’re delivering the benefits of Generative AI quickly and effectively to our customers.”"
  },
  {
    "id": "1834023197365666109-pimco-azure-ai-search-banking-and-capital-markets-en-united-states",
    "content": "November 14, 2024\n\nThe client-facing teams at PIMCO serve hundreds of thousands of clients around the world, all of whom need accurate, up-to-date information on the products they hold. To boost the client experience, PIMCO wanted to help its associates spend less time aggregating data and more time engaging with clients.\n\nTo help associates find relevant information faster, PIMCO built an enterprise tool, named ChatGWM, on Azure AI. ChatGWM is a secure, RAG-based application that searches across PIMCO-approved structured and unstructured data sources to deliver fast, relevant information to its teams.\n\nInstead of searching through documents themselves, associates can now simply type their questions into ChatGWM using advanced search technology to get more insightful responses, fast. ChatGWM also provides the source of its information, helping associates verify that everything is factually correct.\n\nA trusted leader in finance\n\nPIMCO is a global leader in active fixed income with $2 trillion in assets under management (as of September 30, 2024). For over 50 years, the company has served its global client base by investing client capital in income and credit opportunities that span the liquidity spectrum. PIMCO prides itself on its extensive resources, global presence, and time-tested investment processes that are designed to help give clients an edge as they pursue their long-term goals. The markets might change, but PIMCO’s commitment to clients remains the same.\n\nTuring a challenge into an opportunity\n\nPIMCO’s client-facing teams around the world need accurate, up-to-date information on the PIMCO products their clients hold. Responsiveness, as well as quality of content, is critical for client service. “Our clients have such diverse investment needs,” says Matthew Schwarz, Head of Business Strategy and Analytics in US Wealth Management at PIMCO. “When clients call with questions about the specific funds they’re invested in, our teams need to find accurate answers quickly.”\n\nFinding those answers may mean searching through a large number of data sources, depending on the request. This process, when accounting for the high volume of clients across the organization, takes a significant amount of time that could be better spent engaging clients instead of sifting through data. “Improving our data search process by 10%, or even 5%, would drive scale and efficiency across the company,” says Sanket Bafna, Senior Vice President, Head, Client Data Intelligence and Sales Technology at PIMCO. “We saw an opportunity to use AI to enhance associate productivity and improve the client experience.”\n\nAs our needs have grown and evolved, Azure AI has allowed us to start small, start fast, build, test, iterate, and deploy the applications.\n\nSanket Bafna: Senior Vice President, Head, Client Data Intelligence and Sales Technology\n\nPIMCO\n\nPutting Azure AI to work\n\nThe advancement of large language models (LLMs) presented PIMCO an opportunity to further evolve the quantitative capabilities it has used for decades and accelerate the impact of solutions such as the client request search process. So, the team came up with the idea of building a chat interface that could answer questions by searching for relevant information.\n\nBut as a financial services company, PIMCO has strict regulatory requirements around the types of information it can share with clients. All data or statistics must come from the most current monthly or quarterly report, depending on the product. It was crucial the new interface use only PIMCO-approved data when surfacing information. With these guardrails in mind, the company chose Azure AI for its breadth of functionality. “We loved the completeness of vision Microsoft has shown with AI, including security and compliance. Azure AI has allowed us to spend time building solutions instead of building AI plumbing,” says Bafna.\n\nThe solution ended up being a custom tool named ChatGWM. It’s an advanced retrieval augmented generation (RAG) app that boosts the capabilities of LLMs by adding a knowledge retrieval system that provides grounding data. PIMCO built ChatGWM with Azure AI Studio, a comprehensive platform that equips developers with everything they need to build unique GenAI experiences that scale.\n\nWith ChatGWM, Azure AI Document Intelligence takes data sources and breaks (or “chunks”) them into smaller pieces from which it can extract information and find meaning. This extracted information is sent to Azure AI Search, an advanced knowledge retrieval system for enterprise RAG applications, to be effectively processed by an LLM. AI Search then generates embeddings from the data using an Azure OpenAI Service embedding model, enabling semantic similarity search for more nuanced and relevant interactions in the application. The embeddings are stored in a vector index in AI Search. Because AI Search offers retrieval capabilities and seamless data source integrations, ChatGWM is designed to provide responses to every question using the most relevant information.\n\nUsing prompt orchestration in AI Studio, ChatGWM is able to connect workstreams and, because PIMCO stores data across several locations like SharePoint and Box, it uses Azure Logic Apps to make sure files are updated in real time when documents get added or removed. PIMCO is looking forward to utilizing upcoming Azure Cosmos DB features such as Vector Search, Full Text Search, and Semantic re-ranker (RRF).\n\nIn terms of scaling ChatGWM, using Azure has allowed the team to build and mature the platform without needing to change its underlying technology. “As our needs have grown and evolved, Azure AI has allowed us to start small, start fast, build, test, iterate, and deploy the applications. We were able to grow the application on the same stack,” says Bafna.\n\nWe loved the completeness of vision Microsoft has shown with AI, including security and compliance. Azure AI has allowed us to spend time building solutions instead of building AI plumbing.\n\nSanket Bafna: Senior Vice President, Head, Client Data Intelligence and Sales Technology\n\nPIMCO\n\nDriving greater productivity\n\nNow, instead of manually searching folders, files, and databases for information on client products, PIMCO’s client-facing teams will be able to type their questions directly into ChatGWM to receive responses and provide timely and accurate information to clients even faster. ChatGWM also provides the source of its information alongside the response, a feature offered by AI Search, giving teams a quick way to verify that everything is factually correct. They can even download the source documents to share with clients.\n\nWith the ability to ask questions, receive responses, and verify answers all in one place, teams can spend more time engaging clients and having deeper conversations. “Tasks that used to take a lot of time are now so much easier to complete,” says Schwarz. As ChatGWM continues to roll out, PIMCO anticipates saving thousands of hours previously spent on manual processes and improving the client experience.\n\nBased on the success of ChatGWM, PIMCO plans to expand its use of Azure AI Services. By fully embracing the breadth of Azure AI, PIMCO is optimizing internal operations and continuing to improve the client experience."
  },
  {
    "id": "1833247205652391288-legrand-cloud-for-manufacturing-discrete-manufacturing-en-france",
    "content": "Legrand needed tools to help its teams manage complex product data, translating it into multiple languages and keeping it relevant for customers worldwide. Legrand co-developed AI-powered tools Gaia and Elia, using Microsoft Azure OpenAI Service, to streamline product data management and improve customer support. Using Gaia reduced the time to generate product data by 60%, while using Elia improved customer support interactions with fast, accurate information.\n\nKeeping pace with complexity \n\nLegrand, a leader in electrical and digital building infrastructures, powers everyday life by delivering essential products, from lighting controls to wiring devices. But with more than 300,000 products across 90 countries, keeping product information accurate, up-to-date, and globally relevant is a monumental challenge.\n\nManaging this vast array of products is no small feat. Product information must be translated into dozens of languages and updated regularly to meet the needs of customers around the world. Vincent Wang, Chief Digital Officer at Legrand, captures the scale of the task: “With so many product references, it’s a huge challenge at the group level to provide the most correct, relevant data.” \n\nAI-powered tools to transform operations \n\nTo meet this challenge, Legrand collaborated with Artefact’s AI and data specialists to co-develop two powerful tools—Gaia and Elia—developed with Azure OpenAI Service, Azure AI Search, and Azure Data Lake Storage, within Microsoft Cloud for Manufacturing. Microsoft technology was the right choice for Legrand because it offered seamless interoperability, scalability, and an established relationship.\n\nWang says, “Historically, we were already using Microsoft technology. Creating the solution with Microsoft Cloud for Manufacturing provided us with accelerated time to market, easier maintenance, and a strong relationship with local Microsoft teams who are proactive and supportive.”\n\nOn the sales side, Elia is more than just an AI-powered chatbot—it’s a vital tool that improves access to accurate product information. Sales managers and customer service teams now can rely on Elia to quickly provide reliable answers to customer queries, enhancing interactions. As one Legrand customer advisor explains, “The user interface is great. The answers are precise, brief, and explanatory.” \n\nOn the marketing side, Gaia is helping Legrand’s teams generate accurate, localized product descriptions. This personalization ensures that whether the product is presented in Europe, South America, or anywhere else, the content resonates with customers. Gaia also helps ensure product information is optimized for SEO, improving visibility across digital platforms. Wang emphasizes the importance of this: “We need to push data to our local entities. We have about 200. And either we translate it into the local language or we enrich it for local context.” \n\nSpeeding up product data and customer interactions \n\nThe impact of Gaia and Elia has been transformative. By integrating these AI-powered tools, Legrand has dramatically reduced the time spent creating and localizing product content. Gaia cut the time spent generating product data by 60%, and in A/B testing, 82% of Legrand’s marketing managers preferred Gaia’s AI-generated descriptions over manually created ones.\n\nElia has also significantly improved the efficiency of customer service and sales teams, offering quick, accurate access to product information and enhancing the quality and speed of customer interactions. “We estimate that around 20 minutes are saved per sales rep and customer advisor in their day-to-day activities, just because it’s easier to find the information,” says Christophe Sirieix, AI and Data Analytics Manager at Legrand.\n\nBy enabling round-the-clock customer interaction, reducing call volumes, and saving time for sales managers, customer advisors, and marketing teams, Legrand can operate more smoothly and focus on higher-value tasks. Moving beyond automation, these tools have freed Legrand’s teams to concentrate on more valuable aspects of their work, improving both customer experience and employee satisfaction.\n\nWang notes that although AI speeds up processes, human oversight remains essential. “You still have to read through the description, make the corrections if needed, and give your own validation,” he says. \n\nLooking ahead: Building an AI-driven future \n\nLegrand’s journey with Microsoft Cloud for Manufacturing is just beginning. With Gaia and Elia already delivering impressive results, the company is excited about what’s next. These tools are not just about automation—they’re about empowering people, whether it’s an employee working more efficiently or a customer finding exactly what they need. Concludes Wang, “These tools are in line with the slogan of Legrand. We’re trying to improve lives.” \n\nDiscover more about Legrand on Facebook, Instagram, LinkedIn, X/Twitter, and YouTube."
  },
  {
    "id": "1827760360162553656-manchester-azure-higher-education-en-united-kingdom",
    "content": "The University of Manchester is a technology and innovation leader. It is currently exploring how generative AI can power its own operations.\n\nThe University has rolled out Microsoft 365 Copilot to three cohorts of users. It is currently investigating the potential of Copilot for Security.\n\nAcademic staff report phenomenal time savings, enabling them to do more for students. Back-office functions also report productivity gains. Enthusiasm is high to develop new use cases.\n\nWith the right kind of prompt, the right questions, and the right guiding through the exercise, Copilot can be transformative.\n\nAdam Grant: Associate Director for Applications, Data and Strategy\n\nUniversity of Manchester\n\nBuilding on its storied history of innovation and excellence, The University of Manchester is working to be at the forefront of AI innovation and application. That’s why it recently deployed Microsoft 365 Copilot to enable 300 users and worked with Microsoft Consulting Services for Education to explore the potential of generative AI to drive efficiency and sustainability across its operations.\n\n“The University of Manchester makes an important contribution to the city and to the UK,” states PJ Hemmaway, Chief Information Officer at The University of Manchester. “It’s really important that we do that in an efficient and sustainable way across research, teaching, and learning. To help us, we partner strategically and work very closely with Microsoft.”\n\n“We use Microsoft for the majority of our workloads. We’re big users of Azure, Microsoft 365, and SharePoint. A lot of information is already in our Microsoft stack, so it makes sense to use Microsoft 365 Copilot to access that data in a secure way and provide a second-to-none experience for our colleagues.”\n\nDeploying Microsoft 365 Copilot\n\nThe first phase of the Copilot rollout was focused on exploring the value Copilot could create across different functions and for different users in the University.\n\n“We have a lot of legacy technology in our estate,” says Adam Grant, Associate Director for Applications, Data and Strategy at The University of Manchester. “But during the pandemic, Microsoft helped us with the rapid adoption of Teams. Since then, Microsoft 365 has become absolutely fundamental to the way the University works. So, when a tool like Microsoft 365 Copilot comes along, which gives us an opportunity to innovate unencumbered by legacy technology, we are really keen to get onboard with it.”\n\n“It was immediately apparent that there’s a lot of power in Copilot,” Adam Grant continues. “For some people, it’s about productivity. For others, it’s a creative tool; enabling them to quickly generate content. For the research community, it offers a different set of functionalities. Understanding where Copilot can drive value in the different types of activity that happen throughout the University was an important first step.”\n\nEnabling pedagogic best practice to enhance the student experience\n\nOne innovative application of Microsoft 365 Copilot was identified by Professor of Hybrid Learning and Director of Flexible Learning at The University of Manchester, Simon Thomson.\n\nHe says, “We know how important multiple-choice questions are in some subject areas for student learning especially as a formative activity, but I don’t have time to write multiple-choice quizzes all the time. I’ve been using Copilot to construct quizzes of 20 questions with multiple choice answers, including the correct answer and three false answers. Copilot is clever enough that I can instruct Copilot to tailor each one to different learning outcomes, Bloom’s Taxonomies, and study levels. Then Copilot can churn out a multiple-choice quiz in about a minute, saving me hours of work.”\n\nHe adds, “An administrative burden exists around a number of tasks our teaching staff undertake. Copilot enables us to expedite those tasks so we can do more things we know are good for student learning but didn’t have the time to do before. Now I could write 20 questions every week and it wouldn’t be a burden to me. That’s really benefitting our students.”\n\nUsing Copilot to support teaching and research activities\n\nThe University team is very keen to encourage users to share their experiences to spread best practice. As a super user amongst the educators included in the first cohort of 120 Microsoft 365 Copilot users, Simon Thomson has identified several compelling Copilot use cases.\n\nHe says, “In research, asking Copilot to do early analysis of transcript data to pick out key themes helps us move forward more quickly with that process and means we are able to spend more of our time consolidating and deepening our understanding. Copilot can also support the writing of module syllabuses, the development of curriculum content, and fundamental curriculum design functions as well—those are just some of the really quick examples of how I’ve been using Copilot on a day-to-day basis.”\n\nSimon Thomson is now looking forward to using Copilot Agent to create a customised Copilot so other users across the University can interrogate a hybrid learning framework which he has recently developed.\n\nHe says, “It's not about using Copilot to do more work, it's much more about Copilot helping me to do better work.\"\n\nTime savings for back-office functions\n\nTricia Sage is a Programme Management Office Analyst and a member of the strategic change team at The University of Manchester. As part of the first cohort of Microsoft 365 Copilot users, she has brought to life some of the advantages for business support teams.\n\n“Meetings are a heavy administrative burden,” Tricia Sage explains. “When we tested Copilot during an hour-and-a-half meeting with some of the senior leadership, we found that the administrative burden during the meeting was reduced by 98%. There are human checks that need to be completed afterwards but, overall, we calculated a cost saving of 48%.”\n\nMajor gains were also identified when using Copilot with SharePoint. Tricia Sage explains, “I’m a prolific user of SharePoint lists. Even with decades of experience, Copilot surprised me. It can help to build a microsystem with great speed and efficiency. It writes me code that I can put into different fields. If there’s anything tricky, I can ask Copilot and it saves me from raising a ticket with support—so my use of Copilot is saving time for our IT team too.”\n\n“You do need to understand the application first in order to ask Copilot to do the things within it you want to do, but Copilot enables your imagination to go wider,” she continues. “I think, ‘Well, if I can do this, can I do that?’ and, usually, Copilot can. I ask and it comes back with an answer. You can use the technology to improve, improve, improve.”\n\nThat “lightbulb” moment\n\n“I think we’ve all had our own individual lightbulb moment where it becomes apparent how powerful Copilot can potentially be as a technology,” says Adam Grant.\n\n“For me, it was producing a capability model and set of principles for a particular area of university activity. It would usually take a good few days—or, potentially, weeks—to work through and validate. Using Copilot, I had a first draft within 15 minutes. With the right kind of prompt, the right questions, and the right guiding through the exercise, Copilot can be transformative.”\n\nThe challenge the University is now stepping up to meet is how to facilitate this “lightbulb moment” for every colleague in every part of the University.\n\nSharing knowledge throughout the University\n\n“Copilot isn’t a one-size-fits-all solution,” emphasises Paul Gregory, Special Advisor to the CIO, at The University of Manchester. “It’s important to get licences into the hands of as many different job roles and grades as possible to really start to understand the use cases and value. Identify champions who are big supporters of Copilot to get involved in feeding back best practice. And share widely the hints and tips of people who are using it differently every day.”\n\n“Microsoft has helped us explain the security and governance issues internally. It has guided us on best practice and given us real-time insights about what’s happening at other universities. That’s been very helpful,” he adds.\n\nThe University of Manchester has invested time and resources to produce and share support materials to help users get the most from their use of Copilot.\n\nPaul Gregory explains, “Our SharePoint site includes access to internal training materials and links to external training. Microsoft has produced some videos for us as well to help set the scene and give guidance on what makes a good prompt. We have a ‘prompt of the week’ on our SharePoint intranet site, which is sometimes academic, sometimes administrative. We’ve set up a Viva Engage community which has attracted questions—and answers—from users across the University. And we’ve had support from Microsoft on some of the questions which might have been more difficult for us to answer.”\n\nPrompting best practice\n\nSkills development is a key area of focus for the university team, especially around prompt literacy.\n\n“There is a learning curve, because you have to put the right prompts in,” admits Simon Thomson. “Everyone needs to develop prompt literacy. The more precise you can be about what you want Copilot to do, the better the outcome.”\n\nHe offers the example, “I could prompt Copilot to give me the learning outcomes for a particular syllabus and that would be okay. But it would be better if I specified that I need six outcomes at study level five with a mixture of active learning, etc. Yes, the prompt takes more time to write, but I get a better result and it’s still a lot quicker than me doing it all myself from scratch.”\n\nTo aid prompt literacy, The University of Manchester has given all users access to Copilot in Bing. It is encouraging users to login and use Copilot for quick wins when searching the internet. This way, they can build confidence and competency with Copilot prompting.\n\nGetting data governance right\n\nThe other challenge for the team has been around data governance. Adam Grant explains, “Data is the lifeblood for the future adoption of this kind of AI tooling. One benefit of our adoption of Copilot is that, to some extent, it is strengthening some of the efforts we’re making around data governance.”\n\n“We have recently readdressed our internal rights and policies. And we’ve been clear with users that if they feel content has been shared inappropriately with them, they need to report it and how we can help them fix it,” he continues. “The great thing about Microsoft 365 is it comes with lots of tools to help us manage data security and data governance.”\n\nPJ Hemmaway agrees, “We’ve invested heavily in our security posture, our Microsoft Security Score is a bit higher than average, and that’s given us some data and risk insights already. As we move forward, we want to explore the potential of Microsoft Copilot for Security to accelerate those security improvements we’re making.”\n\nGreat feedback from across the University\n\nThe first cohort of users gave their initial feedback on six months of use in July 2024. More than half said Copilot is helping in three key ways: by providing instant access to information, reducing the need to search for it manually; by enhancing communication by drafting emails, reports, and more; and improving productivity by taking over some tasks, freeing users to focus on more creative and complex tasks.\n\nHowever, while the majority are excited by the potential of Microsoft 365 Copilot to improve the way they work, two thirds also said they felt the need for ongoing learning to utilise it properly.\n\n“There’s a lot of enthusiasm for AI generally,” reports Adam Grant. “When people think about the possibilities of integrating generative AI with something that’s already powerful, like Microsoft 365, people imagine a kind of eutopia and they want to get on board straight away. We want to harness that enthusiasm and buzz to establish a collaborative, creative community, in which we encourage people to push boundaries and work out how its applicable to their own scenarios.”\n\nWith this goal in mind, and based on the positive early feedback, the University is steadily increasing the number of Copilot licences from 120 to 200 then 300, enrolling a second and third cohort of users to explore the possibilities. Paul Gregory warns, “When people share their good use cases and productivity savings, all of a sudden, other areas want licences and it creates a bit of a tidal wave.”\n\nConvenience boosts ease of use and return on investment\n\nThe University has found that, because Copilot is embedded in the apps being used every day, it offers a great experience for users.\n\n“For me, the incredible benefit of Copilot is the way it is fully integrated into the Office 365 environment,” enthuses Simon Thomson. “I’ve got to the point now where I’m not even thinking about the fact I’m using AI. I’m just clicking on the Copilot button in the application I’m using, and it is simply facilitating and supporting the work I already do. I don’t have to go anywhere else and then bring the answer in, Copilot helps me right where I need it.”\n\nAlmost all users have reported some productivity gains, although these are varied; they range from 15 minutes per day to more than three hours per day.\n\nPaul Gregory reports, “Through our user feedback, we’ve identified loads of small wins—and they all add up. Saving half an hour with Copilot might not sound like much but, when you look at that over 1,000 people, it’s a big saving.”\n\nThe biggest learning? The need for ongoing education\n\nWhen the second cohort fed back in August 2024, the biggest productivity gains proportionally were for users who had a small amount of manual or repetitive tasks. They offloaded 40% of that work to Copilot.\n\nHowever, this proportion reduced to 18% for those with a significant amount of manual or repetitive tasks (up to 75% of their role). Accompanying qualitative feedback showed that some users were overwhelmed by the possibilities of using Copilot across all their Microsoft 365 apps and emphasised the need for practical prompt suggestions and ongoing learning. The team is actively working to address this feedback.\n\n“We’re getting better at the support we’re putting in place,” admits Paul Gregory. This includes continuing to invest in and promote the dedicated SharePoint site and Viva Community and establishing a Centre of Excellence, as well as continuing to emphasise the need for and build resources for prompt literacy.\n\nTricia Sage recommends, “I’m a strong advocate of owning your own personal development. Experimenting with Copilot has been worth the investment; I wouldn’t want to go without it now. I think the way Copilot stretches your imagination is great.”\n\nA 2030 vision: Expanding the use of AI and Copilot\n\nThe University’s focus is now on how to build on the learning so far. It plans to significantly expand the number of Microsoft 365 Copilot licences available to users and run similar analyses of the potential of Microsoft Copilot for Security, the customisation capabilities of Copilot Agent for advanced users like Simon Thomson. It is already assessing the potential of Microsoft Copilot in Azure and Azure OpenAI Service for research engineers to quickly set up high-performance compute environments for the University’s research community.\n\n“We get a lot of value from our relationship with Microsoft,” says PJ Hemmaway. “Microsoft Security Copilot is an important part of the strategic investment we’re making. And we’re already purchasing more Microsoft 365 Copilot licences. We’re currently in the process of developing our 2030 strategy and Microsoft Copilot will definitely be part of it.”\n\nAs the use cases expand, the team’s approach will continue to emphasise creative thinking and continuous learning—and this will guide communication with and resource creation for the existing and new user base.\n\n“There are almost unlimited possibilities with Microsoft Copilot,” says Adam Grant. “The danger is people think, ‘Alright, that’s how I use this,’ and then they don’t continue to explore. We don’t want people sitting back on their laurels. The challenge now is to encourage people to continue to ask: What else can I use this for?”"
  },
  {
    "id": "1829961572653421022-ctrip-azure-ai-search-travel-and-transportation-zh-chinese",
    "content": "旅游业快速发展，消费者希望能根据自己的兴趣、偏好和需求定制旅行计划,获得更加个性化的旅行体验。携程旗下的Trip.com在满足消费者诉求时，面临着已有产品、数据如何通过生成式人工智能的方式整合进不同场景的业务产品中，如何利用生成式人工智能构建多语言平台，如何利用生成式人工智能实现各类信息问答和服务请求的集成、意图识别和澄清、对话流畅性优化以及外呼机器人衔接等挑战。\n\n在客户服务应用中，Trip.com利用Azure OpenAI强大的语义理解能力，对其客服机器人（Chatbot）系统进行优化，提高查询识别的准确性。 在市场营销场景中，Azure OpenAI的大模型，如GPT4-Turbo，可以深入理解用户的意图和兴趣，并生成个性化的营销内容和推荐文案。 Trip.com以Azure OpenAI为依托，打造智能旅行对话机器人TripGenie，彻底改变消费者的旅行计划和预订流程。 在内部IT培训中，Trip.com使用Azure OpenAI的GPT4-Turbo、Text-embedding-ada等大模型，构建了基于内部IT知识库的问答助手，帮助开发人员快速查找和解决自己遇到的问题。\n\n目前，将Azure OpenAI提供的生成式人工智能与Trip.com各业务此场景应用结合，Trip.com上机酒核心业务的整体自助率已经超过70%，用户体验和满意度显著提升。\n\n关于携程\n\n携程集团是全球领先的一站式旅游服务供应商，旗下拥有Trip.com、携程旅行、Skyscanner和去哪儿网。秉承“追求完美旅程，共建美好世界”的使命，携程集团致力于为世界各地旅客全方位搜罗及整合旅游信息，让用户可以轻松预订旅游产品及服务，做出最适合自己需求的选择。目前，携程集团已经构建起先进成熟的交易平台，包括移动客户端、网页以及24小时全球客户服务支持。同时，通过携程集团丰富的产品及创新的营销策略，合作伙伴及供货商得以接触快速增长的全球用户。其中Trip.com致力于结合生成式人工智能为分布在全球39个国家的境外旅行者提供卓越的智能旅行体验。\n\n业务需求与挑战\n\n随着旅游行业的日益繁荣，消费者的需求也日趋多样化，从传统的观光旅游到如今的深度体验、文化探索等多元化需求，消费者期待能够根据自己的兴趣、偏好和需求定制旅行计划,获得更加个性化的旅行体验。这对旅游服务供应商来说既是机遇也是挑战。对携程来说，如何抓住机遇，通过不断创新和服务升级，来满足消费者多样化的需求，赢得消费者的青睐，是持续保持竞争优势的基础。为了应对这些挑战，携程旗下的Trip.com决定采用微软Azure OpenAI服务，将最新的生成式人工智能技术与其现有的业务场景应用深度结合，通过不断地迭代、创新和优化，使各业务场景的应用系统能够更好地理解消费者的诉求，并借助GPT-4 Turbo 0409、GPT-4o、GPT-4 Turbo with Vision等业界领先的大模型，给消费者提供旅行全生命周期的服务，包括旅行前的目的地探索、行程规划、机酒预定、旅行中的目的地信息问答，以及优质高效的售后服务等。\n\n携程旗下的Trip.com是面向全球市场的一站式的在线旅游服务供应商，拥有全球海量酒店、机票和景点产品，以24种语言服务于39个国家和地区,并支持35种货币。过20多年的发展，Trip.com积累了大量优质旅行线路和高质量的客户服务数据，同时在服务信息、产品资源覆盖等方面也拥有独特的优势，如何将已有的产品和数据优势通过生成式人工智能的方式整合进不同场景的业务产品中以便为消费者提供更有针对性的个性化服务，是Trip.com面临的首要挑战；其次，Trip.com的客户来自全球多个国家，客户咨询的语言有几十种，而旅游场景对信息准确性和服务质量的要求非常高， 如何利用生成式人工智能构建多语言平台，实现一套服务同时支持多种语言的目标,是Trip.com面临的第二个难题；第三，Trip.com提供的旅行服务通常都会涉及到与客户的多轮次沟通，这中间既包括与人工客户的沟通，也包括与自动应答机器人的沟通，如何利用生成式人工智能实现各类信息问答和服务请求的集成、意图识别和澄清、对话流畅性优化以及外呼机器人衔接，这些技术难题对Trip.com来说都是非常具有挑战性的工作。\n\n解决方案与项目实施\n\n为了实现既定的业务目标，Trip.com选择与微软合作，将Azure OpenAI所提供的生成式人工智能服务应用于Trip.com的各业务场景,对客户服务、市场营销、智能旅行对话机器人TripGenie、企业内部IT培训等业务应用系统进行功能迭代和功能创新，所使用的Azure OpenAI主要服务包括Azure OpenAI Code Interpreter、Azure Cognitive Service认知服务、GitHub Copilot、API Management、Azure Cognitive Search认知搜索等。“选择Azure OpenAI不仅使我们可以根据不同的业务场景访问GPT-4 Turbo 0409、GPT-4o、GPT-4 Turbo with Vision等多种大模型，同时也使我们获得了微软智能云Azure的各种企业级功能，包括安全性、合规性、全球化覆盖能力等。此外，Azure OpenAI服务非常易于使用，这使我们可以将时间和精力专注于业务迭代和功能创新，仅用了数月时间就完成了各场景业务应用系统的重构。” 携程集团高级研发总监蔡峰说。\n\n从2023年开始，Trip.com分别在以下四个业务场景应用中引入了Azure OpenAI的相关服务并达成了预期的目标。\n\n场景一：客户服务\n\n    在客户服务应用中，Trip.com利用Azure OpenAI强大的语义理解能力，对其客服机器人（Chatbot）系统进行了针对性的优化，提高了查询识别的准确性，使机器人自助率得到明显提升。在这一应用场景中，Trip.com采用了GPT 3.5-Turbo、GPT4、GPT4-turbo、Text-davinci-003等大模型。\n\n    Trip.com的用户来自全球各地，多语言支持是必不可少的。Azure OpenAI的大模型，如GPT-4和GPT-3.5-Turbo等，能够处理跨语种的文本，包括翻译、摘要、问答等任务,用户可以将一种语言的文本输入到模型中，模型能够生成另一种语言的相应输出，轻松实现跨语种的交流和理解，这种多语种支持能力不仅使Trip.com快速构建起跨语种的客服机器人，同时还达成了用一套处理引擎处理全球多语种客户咨询的目标，从而使Trip.com客户服务的邮件响应速度从小时级别提升到分钟级别，用户体验和满意度显著提升。\n\n 场景二：市场营销\n\n市场营销的效果直接关系到Trip.com的客户粘度，Azure OpenAI的大模型，如GPT4-Turbo，可以深入理解用户的意图和兴趣，并生成个性化的营销内容和推荐文案。例如，采用了Azure OpenAI大模型的市场营销应用可以利用Azure OpenAI的多语言支持能力，将一种语言的内容转写成多种语言的内容，极大地提高了内容生产的效率。\n\n场景三：智能旅行对话机器人TripGenie\n\nTripGenie是Trip.com以Azure OpenAI为依托，并融合携程集团多年来积累下来的业务数据和业务API，打造的一款高级AI旅行助手，旨在彻底改变消费者的旅行计划和预订流程。\n\nTripGenie基于Azure OpenAI的GPT系列大语言模型，通过将人工智能驱动的行程规划与所有类型的预订相结合,为消费者提供了一个针对个人需求的一体化旅行管理解决方案，消费者只要提出与旅行相关的复杂或模糊的问题，就能获得准确的答复，TripGenie会根据消费者的问题，生成从旅行开始到旅行结束的完整旅行计划，包括旅行线路、行程、景点、机票/车票、酒店预定等。例如，消费者告诉TripGenie ：“我打算8月初带老人小孩一起到法国旅游，最好是能去哪个有薰衣草的地方，我们预计一周左右，总体预算在8000美金”，依据这些信息，TripGenie会判断出消费者要去普罗旺斯、时间7天左右、总预算8000美金；接下来TripGenie会跟消费者澄清出行人数、酒店住宿安排，以及目的地交通方式（包车、自驾、还是参团），经过沟通获得确定信息后，TripGenie就会到Trip.com平台查询对应资源，如果价格超出预算，还需要跟消费者协商时间是否可以灵活调整，比如早一点或晚一点出发，时间是否可以缩短一天等，最终帮助消费者完成与本次旅行相关的预定。\n\n场景四：内部IT培训\n\n借助生成式人工智能等最新技术来完成业务应用的迭代、创新，必然对IT团队提出了更高的要求。为此， Trip.com使用Azure OpenAI的GPT4-Turbo、Text-embedding-ada等大模型，构建了基于内部IT知识库的问答助手，帮助开发人员通过交互查询方式,快速查找和解决自己遇到的问题。例如，Trip.com构建的开发文档助手，对公司内部框架类开发知识进行切片和Embedding处理，再通过RAG方式提供问答服务，快速高效地满足开发人员的知识查找需求。\n\n获得的成效\n\n将Azure OpenAI提供的生成式人工智能与Trip.com各业务此场景应用结合，使Trip.com在服务客户和推动自身业务的发展两方面都获益匪浅。\n\n在客户服务方面，Azure OpenAI加持的机器人客服系统可以通过自然语言与客户沟通，能更好地理解客户的诉求，并快速为客户提供准确的答复，这使得客户可以更方便快捷地获取全球的旅行攻略内容，使旅行攻略的制定更为轻松。TripGenie为客户提供的一站式行程规划服务涵盖了旅行前的目的地探索、行程规划,旅行中的目的地信息问答、机酒信息，以及高效及时的售后服务，极大地提升了客户出行的便利性。目前Trip.com上机酒核心业务的整体自助率已经超过70%。\n\n在Trip.com自身业务发展方面，Azure OpenAI生成式人工智能的引入，提高了市场营销内容的生成效率，并且可以提供更有针对性内容和图片；在内部人员培训方面，利用Azure OpenAI构建的知识库使开发人员能大幅度提升学习、了解新知识的效率，更快地完成个业务系统的升级迭代。"
  },
  {
    "id": "1825988149746373274-bradesco-azure-ai-services-banking-and-capital-markets-en-brazil",
    "content": "Bradesco Bank, one of the largest financial organizations in Brazil, was looking to enhance its virtual assistant, BIA, with Microsoft Azure’s generative AI in order to improve its efficiency and resolution capacity.\n\nBradesco Bank has integrated Microsoft Azure’s generative AI to its virtual assistant, BIA, leveraging services such as Azure OpenAI and Data Lake to improve its efficiency and resolution capacity.\n\nThe implementation of Microsoft Azure’s generative AI by Bradesco resulted in a reduction in the response time from days to hours and an 8x growth in the use of BIA, significantly improving the operational efficiency and client satisfaction.\n\nFrom days to a few hours: The agility and efficiency of generative AI\n\nIn 2016, Bradesco introduced BIA (Bradesco Artificial Intelligence), a virtual assistant that quickly became popular among clients. With the emergence of generative AI, Bradesco aimed to stay ahead of the curve. In November 2023, the bank made a significant leap by integrating Microsoft Azure's generative AI into BIA Agências, a version tailored for branch managers. Initially, this advanced technology was available to a select group of employees, showcasing Bradesco's commitment to innovation and efficiency.\n\nThis integration leverages the full Microsoft Azure suite, including Microsoft Azure AI Services, Microsoft AI Search, Microsoft OpenAI Services, Microsoft Data Lake Storage, Microsoft Azure Databricks, and Microsoft Azure Service Fabric, all while adhering to security and responsible AI principles. After a successful 3-month experiment, the solution was ready and gradually rolled out to managers and employees. Phelipi Dal’Olio Santos, Data Manager at Bradesco, highlighted the challenge: \"It was very new and challenging. We had to make a solution in a dynamic market with many changes, but we successfully brought all these innovations to BIA.\"\n\nTo streamline queries on internal regulations and boost managers' productivity, Bradesco harnessed the power of generative AI to quickly and accurately generate answers and documents, eliminating time-consuming queries. According to Augusto Vieira, Data Manager at Bradesco, updating answers and documents used to take 3-5 days. Now, this process is reduced to just a few hours or even overnight. This agility not only enhances operational efficiency but also cuts costs associated with lengthy and complex processes.\n\nBIA has also been launched to digital clients, and the initial results from using generative AI are already evident. In the first week, Bradesco achieved impressive numbers: an 82% resolution rate at the first level of service and an 89% retention rate, directly enhancing the self-service experience available to clients through digital channels.\n\n8x more queries: The reliability of generative AI\n\nAnother success indicator was the notable increase in the frequency of use of BIA Agências by managers. Vieira revealed that the number of queries made by managers surged 8x after the implementation of generative AI. \"They are returning more and asking more,\" he stated, highlighting the high level of trust in the new technology.\n\nTestimonials from branch managers who experienced a transformation in their work with BIA Agências further underscore its impact. A.G., General Manager, noted, \"BIA provided correct answers, even for matters we don't frequently ask about.\" AOC, Service Operator, shared, \"From now on, I will ask BIA as though they’re my work colleague.\" An Assistant Manager of the digital branch added, \"It's excellent not having to close BIA to change the subject.\"\n\nThe effectiveness of both BIA Agências and BIA Clientes was evident in the improved accuracy and contextual relevance of the answers, which enhanced customer satisfaction and service quality. As Phelipi emphasized, \"BIA becomes an ally to the manager, acting as a copilot and providing greater resolution to our clients.\"\n\nA successful strategic partnership\n\nBradesco underscores the pivotal role of Microsoft as an essential partner in their project's success. Vieira noted, \" Microsoft brought some base architecture, and in all the challenges we faced while building this journey, Microsoft readily answered and supported us in solving them.” This continuous collaboration ensured Bradesco had access to top-tier technologies and technical support.\n\nThe integration of Microsoft Azure's generative AI has positioned Bradesco as a leader in financial sector innovation. BIA stands out as a benchmark for AI use in financial organizations, reinforcing Bradesco's market image and inspiring other organizations to follow suit.\n\nNext steps: The evolution of generative AI\n\nThe future of generative AI at Bradesco is bright. The bank plans to expand BIA's use to its entire client base. This evolution will enable BIA to not only provide information but also perform more transactional actions, further streamlining processes and enhancing the customer experience.\n\nConclusion\n\nThe implementation of Microsoft Azure’s generative AI by Bradesco exemplifies how technological innovation can transform processes and enhance efficiency in large financial organizations. With significant productivity gains and improved service quality, Bradesco stands out as a leader in AI adoption. As Vieira concluded, “We are expanding, taking the lead, and bringing value to the market with all our lessons so far. The fact that this is already a reality makes us proud.”"
  },
  {
    "id": "1825642148546862376-capitec-bank-power-bi-banking-and-capital-markets-en-south-africa",
    "content": "Capitec Bank, South Africa’s largest retail bank centered on customers, strives to keep things simple, affordable, and accessible. The bank's Head of Data Transformation wanted to make things even simpler for employees.\n\nStarting with Copilot for Power BI, exploring Copilot Studio, and graduating with Azure OpenAI, Capitec streamlined a number of processes across various departments in the bank.\n\nWith Copilot and Azure OpenAI Service, Capitec’s employees save one hour per week, enhancing efficiency and driving innovation across departments\n\nEstablished in 2001, Capitec Bank serves over 22 million clients with a focus on simplicity, affordability, and accessibility. Operating 850+ branches and employing more than 16,000 people, it continuously explores technology to serve clients better and simplify its operations. \"At Capitec, we continuously push the boundaries, question conventions, and adapt to the growing demands of our clients. ‘Better never rests’ embodies our unwavering commitment to excellence, constant improvement and forward momentum,\" explains Michael O'Carroll, Head of Data Transformation at Capitec Bank.\n\nGradual yet decisive change\n\nAs an early adopter of technologies, O’Carroll has always been fascinated with AI. He started experimenting with custom chatbots 10 years ago and today leads a company-wide effort to improve efficiency and augment employee capabilities with GenAI. “Generative Al has the potential to catalyze an era of transformation. It stands to reshape industries, enhance productivity, and forge new paradigms of innovation and human-machine collaboration,” O’Carroll shares. Leading a small team of engineers, instructional designers, and change managers in a transformation office, he steers discussions on the latest generative AI technologies. “I work with various departments—marketing, HR, finance, audit, risk, and product teams—who come to me with ideas for generative AI use cases. In each area, I’ve set up a champion or lead driver who identifies, explores and prioritizes use cases,” he adds.\n\nHowever, Capitec treads carefully when introducing new generative AI tools, aiming to manage risks, drive responsible use, and always keep a human in the loop. So, the bank employs the ADKAR (Awareness, Desire, Knowledge, Ability, and Reinforcement) model of change management, ensuring that employees have the necessary skills, knowledge, and motivation to adopt these AI tools. “Generative Al has potential to enhance client experience and increase operational efficiency. By aligning these goals with individual roles, the transformation feels relevant and beneficial to employees,” shares O’Carroll. With initiatives like creating a Centre of Excellence and a Community of Practice, the company gradually builds employee capacity and knowledge in Generative AI \n\nExploring AI solutions\n\nWith this calculated approach, Capitec Bank started introducing generative AI solutions. By integrating Copilot with Smart Narrative in Power BI, O'Carroll saw an opportunity to automatically generate insights on the daily reports used across the bank’s 850 branches. Staff previously received Power BI reports with pages of data, which had to be manually reviewed before meetings. “Using Microsoft 365 Copilot’s Smart Narrative feature, the reporting process was streamlined. Now, people just click a button, and Copilot generates a report summary for consideration,\" highlights O'Carroll. “It was a good first project because it scaled easily. We have 850 branches with about 10 to 20 people in each, so a huge number of people quickly realized the benefits of Copilot.”\n\nCapitec Bank’s adoption of Copilot continued to expand with Microsoft 365 Copilot. “Microsoft 365 Copilot enabled our people to test, play, and run their own prompts in a fairly low-risk environment, streamlining internal processes. We ran hundreds of demos, building enthusiasm among our staff for Microsoft 365 Copilot,” shares O’Carroll.\n\nCapitec also saw how extending Copilot with a finance agent could further unlock efficiencies. One striking example involved a finance team member who was responsible for a reconciliation process. \"It previously took her six hours each week to run her reconciliations. It involved too many lookup formulas, and she was constantly stressed,\" says O’Carroll. Capitec turned to Microsoft 365 Copilot for Finance, a Copilot agent purpose-built to support financial processes. “With Microsoft 365 Copilot for Finance, the reconciliation process was reduced to just one minute per session, saving our colleague six hours a week. And the fact that she now trusts the process makes a big difference.\"\n\nBuilding solutions from scratch\n\nSeeking to develop even more advanced AI solutions, Capitec Bank turned to Microsoft Copilot Studio to build custom copilots. “Copilot Studio gave us a well-packaged, safe, and secure platform within Microsoft 365 to learn, grow, and explore,” O’Carroll describes. “Copilot Studio remains cost-effective and low maintenance, making it a good steppingstone in our journey.”\n\nOnce the team grew comfortable with the capabilities of Copilot Studio, their ambitions grew bigger. “We realized that if we’re going to scale, we would need a bigger platform. Azure OpenAI Service made sense,” recalls O’Carroll. It took about a month of learning to get the first solution running. As the bank’s GenAI Center of Excellence developed, it became far more efficient. “Previously, it took a month to get a chatbot running on Azure OpenAI. Now, we can do it in a day because we’ve built the capacity to support development, monitoring, and testing,” O’Carroll shares. This increased agility enabled Capitec to experiment rapidly, implementing Generative AI-driven solutions across the business.\n\nCross-departmental improvements\n\nO’Carroll worked with various departments like marketing, human resources (HR), finance, and risk management to implement Generative AI solutions tailored to their needs. One such bespoke solution is for customer service consultants within the branch. “A client might ask about a specific product, and the branch staff might not have memorized that item,” elaborates O’Carroll. “So, we’ve implemented a chatbot using Azure OpenAI, which will be available on every branch employee’s screen. It has 1,000 product-related questions along with answers stored in a database, so people can just engage the chatbot and respond quicker to clients, serving them better, and selling more effectively.” The bank is now experimenting with adding the speech-to-text capability to the agent, empowering teams to talk to the chatbot. “Direct speech engagement to our data assets will open up a myriad of new transformation initiatives as we can now talk to our data,” O’Carroll adds.\n\nAnother example relates to the chatbot that was developed on Azure OpenAI and grounded with the last 5 years of bank’s integrated annual reports. “This has enabled teams within Capitec Bank to review how they can enhance sustainability reporting against global standards like the Global Reporting Initiative (GRI). This ultimately enables us to enhance the quality of information that we disclose to the market,” O’Carroll adds.\n\nIn other examples, the communication team started generating unique images tailored to its clients and the South African market with models like DalleE3, instead of using generic stock images. “We’ve created amazing imagery for internal communications,” shares O’Carroll. The legal team started analyzing contracts with Generative AI, extracting information from contracts and comparing it against the bank’s criteria. The human resources team began perfecting job descriptions and reviewing resumes faster with Generative AI. The audit team also uses Copilot to explore optimized risk control reviews and testing processes.\n\nThe bank also used Azure Open AI to develop a Copy-write chatbot which is being used to review and rewrite internal content using the bank’s specific style, tone and writing requirements. “This agent helps to standardize how we communicate with our teams and improve the speed at which new content is generated, reviewed and approved,” O’Carroll says.\n\nWith Generative AI solutions being implemented across various departments, teams soon started noticing efficiency gains. “We did a survey that revealed around 80% of our staff with access to Microsoft 365 Copilot save an hour per week. Some of the respondents are saving up to five hours a week,” O’Carroll points.\n\nFor O’Carroll, the key benefit is empowering employees to achieve more. “It’s not only about efficiency but also about increasing creativity and innovation,” he shares. “A lot of tasks that were previously impossible are now achievable with our Generative AI. This process has demonstrated that these tools can transform our operations and push boundaries in ways we hadn’t considered before.”\n\nLooking ahead to future success\n\nAs Capitec Bank looks to the future, it recognizes that Generative AI will require a strong foundation. “Our strategy now is to continue building a solid governance framework for the responsible use of Generative AI. We've rewritten our responsible Generative AI usage standard, developed trainings and began revising job descriptions,” O’Carroll emphasizes. This approach will ensure that everyone in the bank, from entry-level employees to the chief operating officer, is equipped to handle Generative AI responsibly. “As our use-cases mature, we will be able to run even faster and enable more innovation across the bank,” O’Carroll says.\n\nBeyond augmented workforce, Capitec’s Generative AI initiatives have sparked new opportunities in areas the bank hadn’t previously considered, such as search engine and large language model optimization. By improving how clients search for information about products and services, the bank continues to refine its client engagement strategies. “Copilot sparked a new way of thinking,” O’Carroll shares. “This shift in perspective has led us to rethink processes, embrace innovation, and embed Generative AI throughout the bank’s operations, laying the groundwork for future success.”"
  },
  {
    "id": "1823448586265567812-mpgtalentsolutions-azure-open-ai-service-professional-services-en-france",
    "content": "ManpowerGroup’s Talent Solutions practice was in search of a solution for gathering and analyzing HR data to power its consulting practice, which was previously a time-consuming process that impeded workforce planning. \n\nThe business used Microsoft Power Platform to create a solution that helps clients gather and analyze data. Data is displayed in Power BI and uses Power Platform dataflows and Azure OpenAI Service to create a holistic picture of workforce needs.  \n\nThe solution helped support improved HR planning and save costs compared to other strategic workforce planning (SWP) solutions. Consultants spend more time helping employees find new jobs, rather than compiling data and creating reports. \n\nFounded in 1948, ManpowerGroup is a leading global workforce solutions company. It is made up of three global brands, including Talent Solutions, which focuses on talent acquisition, development, and retention. Talent Solutions also offers workforce planning, which helps organizations identify current and future talent needs—and stay ahead of skills gaps.   \n\nOne of the challenges with workforce planning is pulling all relevant data together. This often includes data from multiple systems, from internal HR and budgeting systems to external sources for job market data. It can take months to assemble the data, which is often outdated by the time a plan is constructed. Talent Solutions wanted to deliver faster, more impactful planning services to its customers. For that, a more advanced process using workforce planning software would be required.  \n\nCreating a low-cost alternative to traditional SWP solutions \n\nThere are many strategic workforce planning (SWP) software products available off the shelf but none that fit Talent Solutions’ needs. “We wanted a solution that was more customizable, because we know each customer has their own way of looking at HR data,” says Kevin Palop, Director of Operations for the Data and Digital Factory, ManpowerGroup Talent Solutions France—the team that created the solution.  \n\nPalop, who had worked on similar software at other companies, knew that customized SWP software can take months, even years, to develop. Talent Solutions wanted a solution faster and at lower cost without having to engage external software development resources. To help meet this challenge, the team turned to Microsoft Power Platform. As Palop says, “We aren’t a software company, so we have to adapt, using the technologies we have at hand. We were already using Power Platform and, as we quickly discovered, we could cover all the functionalities we needed to build an effective workforce planning solution.” Ultimately, the SWP solution was built by five developers on the Data & Digital Factory (D2F) team in France. Created to provide digital solutions using Power Platform, D2F completed the solution in just two months. \n\nFrom data structuring to AI-driven analysis  \n\nThe SWP solution developed by the company streamlines the entire planning process, providing greater visibility and hands-on planning options to all users. Customers start by loading data into SharePoint. Power Platform dataflows—self-service, cloud-based data preparation technology—are then used to ingest, transform, and load data into Microsoft Dataverse environments. Romain Chamot, Head of Data and Digital Factory, ManpowerGroup Talent Solutions France, says, “What we love about the Power Platform solution is that, no matter what the data source, we can use dataflows to extract a diverse set of data, and then we can structure it in for analysis.”  \n\nStructuring data often involves adding missing elements to complete a record. In many cases, for example, customers will list job roles required but not include the related skills. To add this missing data, the system is connected to baseline references (for example, the ROME job reference in France). Interoperation with Azure OpenAI Service then matches skills with the jobs listing to augment customer data and provide a more complete picture of a customer’s HR requirements. This is done using similarity-embedding models in Azure OpenAI, which capture semantic similarity between text pieces. \n\nAlong with customer data, the system brings together job market and regulatory data (such as new employment laws), along with ManpowerGroup’s own market intelligence to enable projections on job demand and supply, attrition rates, and other data trends needed for benchmarking and planning. Integration across HR and finance systems enables budget forecasting against predefined strategies.  \n\nTo build out planning scenarios, consultants and customers use a model-driven app built with Microsoft Power Apps and interoperable with Dataverse. This app also enables users to update or change planning objectives and modify information in Dataverse. The impact of these changes is displayed in Power BI. Customers can also easily layer on data to see how a plan is progressing against original objectives. Localized apps enable operational HR managers to visualize the impact a central strategy has on their teams and create their action plan. For users who prefer to work with the data in Excel, a Power Automate flow exports the data into a spreadsheet and can also import it back into Dataverse.  \n\nThe SWP solution also takes advantage of powerful AI capabilities. Using data analysis and Azure OpenAI embeddings, the system can calculate the percentage of employees that can be deployed to other jobs in a company, based on their specific skill set. Similarly, AI is used to match employees with job opportunities outside the company. In this way, the platform has helped expand the services offered by Talent Solutions to include individual career coaching during downsizing and other career-shifting scenarios.  \n\nPreparing competency reports for this type of coaching used to take hours. With the SWP system, these same reports can be generated in a fraction of the time. “In five minutes, our SWP system can generate a competency report, which can be very helpful for an employee to find a new job. With faster reports, our Power Platform–based SWP system also enables our consultants to devote more time to one-on-one coaching and career planning,” says Alix Baissac, HR Project Manager at ManpowerGroup Talent Solutions France.  \n\nThe benefits of faster, deeper analysis \n\nThe company’s SWP solution has been deployed with multiple customers and has delivered tremendous value. First, the solution has made it easier to assemble and analyze data, accelerating the workforce planning process from months down to just weeks. The tool makes it easier to view, share, and analyze data with colleagues which, in turn, enables them to move faster from resource planning to execution. “Customers are seeing the huge potential, having a centralized view on their whole workforce through our Power Platform solution,” says Caroline Pfeiffer, Senior Vice President at Right Management, a division of Talent Solutions. “With Power Platform, we’re not only able to provide deeper analysis of data but make it available to more people involved in the process. This creates a more effective link between planning and execution.”\n\nThe solution is also benefiting Talent Solutions directly. With faster and deeper analysis, both the number and length of engagements with existing and new clients have increased.\n\nOriginally created for the French market, the SWP solution is now set to be used globally across the ManpowerGroup network. At the same time, the D2F team is fielding requests for other Power Platform solutions for other divisions, including low-code add-ons for other Microsoft systems used by the company, such as Dynamics 365 CRM. “Our Power Platform development practice has grown much faster than we originally anticipated—and that’s a great thing for the business,” says Chamot.\n\nConcludes Sebastien Van Dyk, General Manager at ManpowerGroup Talent Solutions France, “ManpowerGroup Talent Solutions has designed a balanced approach, from vision to operations, that supports companies in aligning HR strategy with business ambitions while ensuring employer social responsibility through social innovation. Thanks to our SWP platform based on Microsoft tools, we leverage the power of data to build tomorrow’s workforce by combining the best skills and talents.” \n\nFind out more about ManpowerGroup Talent Solutions on LinkedIn and X."
  }
]